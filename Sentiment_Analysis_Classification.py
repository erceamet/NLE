# a lot of importsimport nltkimport randomimport stringfrom nltk.classify import accuracyfrom nltk.classify.scikitlearn import SklearnClassifierfrom nltk.corpus import movie_reviews, stopwordsfrom sklearn.svm import SVCfrom sklearn.naive_bayes import MultinomialNB , BernoulliNBfrom sklearn.metrics import precision_score, recall_score,accuracy_score,f1_score# Getting the documentsdocuments = [(list(movie_reviews.words(fileid)), category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]# Shuffling the documentsrandom.shuffle(documents)all_words = []for w in movie_reviews.words(): all_words.append(w.lower()) all_words = nltk.FreqDist(all_words)# Adding stopwords into variable (!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~stopwords_english = stopwords.words("english")# Removing both stopwords and punctuation from the list of words# process also known as 'data cleaning'all_words_clean = []for word in all_words:    if word not in stopwords_english and word not in string.punctuation:        all_words_clean.append(word)# all words freq for the clean wordsall_words_frequency = nltk.FreqDist(all_words_clean)# Extracting the 3000 most common wordsword_features = list(all_words_frequency)[:3000]# Function for finding the top 3000 words in our positive and negative documents,# marking their presence with yes or no.def find_features(document):    words = set(document)    features = {}    for w in word_features:        features[w] = (w in words)    return featuresfeaturesets = [(find_features(rev), category) for (rev, category) in documents]# Training datatraining_set = featuresets[:1900]# Testing datatesting_set = featuresets[1900:]# CLASSIFYING USING NAIVE BAYESprint("Classifying with Naive Bayes...")classifier = nltk.NaiveBayesClassifier.train(training_set)nltkAccuracy = nltk.classify.accuracy(classifier, testing_set)print("Naive Bayes Classifier Accuracy: {:.1f}%".format(nltkAccuracy*100))#classifier.show_most_informative_features(30)# CLASSIFYING USING SVC/SVMprint()print("Classifying with SVC...")model = SklearnClassifier(SVC(kernel = "linear"))model.train(training_set)svmAccuracy = nltk.classify.accuracy(model, testing_set)print("SVC/SVM Accuracy : {:.1f}%".format(svmAccuracy*100))# CLASSIFYING USING BERNOULLI NAIVE BAYESprint()print("Classifying with BernoulliNB...")BernoulliNB_classifier = SklearnClassifier(BernoulliNB())BernoulliNB_classifier.train(training_set)bnbAccuracy = nltk.classify.accuracy (BernoulliNB_classifier, testing_set)print("BernoulliNB_classifier Accuracy: {:.1f}%".format(bnbAccuracy*100))# CLASSIFYING USING MULTINOMIAL NAIVE BAYESprint()print("Classifying with MultinomialNB...")      MNB_classifier = SklearnClassifier(MultinomialNB())MNB_classifier .train (training_set)mnbAccuracy = nltk.classify.accuracy (MNB_classifier, testing_set)print("MultinomialNB Accuracy: {:.1f}%".format(mnbAccuracy*100))# Function for calculating the precision, recall and f1def evaluate (pairs, pos_label):    predicted, actual = zip(*pairs)    # calculating the precision, recall and f1 score using the sklearn.metrics    precision = precision_score(actual,predicted,pos_label=pos_label)    recall = recall_score(actual,predicted,pos_label=pos_label)    f1 = f1_score(actual,predicted,pos_label=pos_label)    # printing the evaluation using the print_eval function    print_eval(precision, recall, f1, pos_label)# Function for printing the precision, recall and f1def print_eval (precision, recall, f1, pos_label):    print()    print("Evaluation for pos_label = %s" % pos_label)    print ("Precision: {:.1f}%".format(precision*100))    print ("Recall: {:.1f}%".format(recall*100))    print ("F1: {:.1f}%".format(f1*100))print()print("Getting the precision, recall and f1 for pos and neg labels...")# Creating pairspairs = [(classifier.classify(sample), actual)            for (sample, actual) in testing_set]# Evaluating pair where label is 'pos' or 'neg'evaluate(pairs, pos_label="pos")evaluate(pairs, pos_label="neg")